{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìÑ PDF Extraction Pipeline for RAG\n",
        "\n",
        "This notebook runs the complete PDF extraction pipeline on **Google Colab** with GPU acceleration.\n",
        "\n",
        "**Pipeline Phases:**\n",
        "1. **Phase 1**: PDF ‚Üí Markdown extraction (Marker ML)\n",
        "2. **Phase 2-3**: PubMed metadata enrichment & validation\n",
        "3. **Phase 4**: JSONL generation for vector databases\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"üîå Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "print(\"‚úÖ Drive mounted!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure project path - UPDATE THIS to your folder name\n",
        "PROJECT_FOLDER = \"pdf_extraction\"  # Change if your folder has a different name\n",
        "\n",
        "project_path = f\"/content/drive/MyDrive/{PROJECT_FOLDER}\"\n",
        "\n",
        "# Navigate to project\n",
        "%cd {project_path}\n",
        "\n",
        "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
        "print(\"\\nüìÅ Project files:\")\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "print(\"This may take a few minutes on first run.\\n\")\n",
        "\n",
        "!pip install -q marker-pdf pydantic pypdfium2 requests\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify GPU is available\n",
        "import torch\n",
        "\n",
        "print(\"üîç Checking hardware...\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"‚úÖ GPU detected: {gpu_name}\")\n",
        "    print(\"   Pipeline will use GPU acceleration (10-20x faster)\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected. Pipeline will run on CPU (slower).\")\n",
        "    print(\"   Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì• Check Input PDFs\n",
        "\n",
        "Make sure your PDFs are in the `data/raw/` folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check input PDFs\n",
        "import glob\n",
        "\n",
        "pdf_files = glob.glob(\"data/raw/*.pdf\")\n",
        "\n",
        "print(f\"üìÑ Found {len(pdf_files)} PDF(s) in data/raw/\")\n",
        "\n",
        "if pdf_files:\n",
        "    print(\"\\nFiles:\")\n",
        "    for f in pdf_files[:10]:  # Show first 10\n",
        "        print(f\"   - {os.path.basename(f)}\")\n",
        "    if len(pdf_files) > 10:\n",
        "        print(f\"   ... and {len(pdf_files) - 10} more\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è No PDFs found!\")\n",
        "    print(\"   Upload PDFs to: data/raw/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üöÄ Phase 1: PDF Extraction\n",
        "\n",
        "Extracts text from PDFs using the **Marker** ML library with GPU acceleration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üöÄ Starting Phase 1: PDF Extraction\")\n",
        "print(\"=\" * 50)\n",
        "print(\"This may take several minutes depending on PDF count.\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "!python pdf_marker_extraction.py\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"‚úÖ Phase 1 complete!\")\n",
        "print(\"   Output: data/marker_outputs/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Phase 1 output\n",
        "json_files = glob.glob(\"data/marker_outputs/*.json\")\n",
        "print(f\"üìä Phase 1 produced {len(json_files)} JSON file(s)\")\n",
        "\n",
        "if json_files:\n",
        "    # Show sample\n",
        "    import json\n",
        "    with open(json_files[0], 'r') as f:\n",
        "        sample = json.load(f)\n",
        "    print(f\"\\nüìÑ Sample output from: {os.path.basename(json_files[0])}\")\n",
        "    print(f\"   Title: {sample.get('metadata', {}).get('title', 'N/A')[:60]}...\")\n",
        "    print(f\"   DOI: {sample.get('metadata', {}).get('doi', 'N/A')}\")\n",
        "    print(f\"   Text length: {len(sample.get('text', '')):,} chars\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üîç Phase 2-3: PubMed Enrichment\n",
        "\n",
        "Validates and enriches metadata using the **PubMed E-utilities API**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Set PubMed API key for faster processing\n",
        "# Get free API key: https://www.ncbi.nlm.nih.gov/account/\n",
        "\n",
        "# Uncomment and fill in if you have an API key:\n",
        "# os.environ[\"PUBMED_API_KEY\"] = \"your_api_key_here\"\n",
        "# os.environ[\"PUBMED_EMAIL\"] = \"your@email.com\"\n",
        "\n",
        "print(\"‚ÑπÔ∏è PubMed API configuration:\")\n",
        "if os.environ.get(\"PUBMED_API_KEY\"):\n",
        "    print(\"   ‚úÖ API key set (10 requests/sec)\")\n",
        "else:\n",
        "    print(\"   ‚ö†Ô∏è No API key (3 requests/sec)\")\n",
        "    print(\"   Set PUBMED_API_KEY for faster processing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üîç Starting Phase 2-3: PubMed Enrichment\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "!python pubmed_enrichment.py\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"‚úÖ Phase 2-3 complete!\")\n",
        "print(\"   Output: data/processed/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check Phase 2-3 output\n",
        "final_files = glob.glob(\"data/processed/*_final.json\")\n",
        "failed_files = glob.glob(\"data/failed/*.json\")\n",
        "\n",
        "print(f\"üìä Phase 2-3 results:\")\n",
        "print(f\"   ‚úÖ Successful: {len(final_files)}\")\n",
        "print(f\"   ‚ùå Failed: {len(failed_files)}\")\n",
        "\n",
        "if final_files:\n",
        "    # Show sample\n",
        "    with open(final_files[0], 'r') as f:\n",
        "        sample = json.load(f)\n",
        "    print(f\"\\nüìÑ Sample enriched document:\")\n",
        "    print(f\"   Title: {sample.get('Title', 'N/A')[:60]}...\")\n",
        "    print(f\"   Link: {sample.get('Link', 'N/A')}\")\n",
        "    print(f\"   Citation: {sample.get('Citation', 'N/A')[:80]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üì¶ Phase 4: Generate JSONL\n",
        "\n",
        "Combines all documents into a single JSONL file for database ingestion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üì¶ Starting Phase 4: JSONL Generation\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "!python combine_json_to_jsonl.py\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"‚úÖ Phase 4 complete!\")\n",
        "print(\"   Output: Output/pdf_extraction.jsonl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify final output\n",
        "output_file = \"Output/pdf_extraction.jsonl\"\n",
        "\n",
        "if os.path.exists(output_file):\n",
        "    with open(output_file, 'r') as f:\n",
        "        line_count = sum(1 for _ in f)\n",
        "    \n",
        "    size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
        "    \n",
        "    print(\"üìä Final JSONL file:\")\n",
        "    print(f\"   Documents: {line_count}\")\n",
        "    print(f\"   Size: {size_mb:.2f} MB\")\n",
        "    print(f\"   Path: {output_file}\")\n",
        "    \n",
        "    with open(output_file, 'r') as f:\n",
        "        first_line = json.loads(f.readline())\n",
        "    print(f\"\\nüìÑ Document fields:\")\n",
        "    for key in first_line.keys():\n",
        "        print(f\"   - {key}\")\n",
        "else:\n",
        "    print(\"‚ùå Output file not found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ‚úÖ Pipeline Complete!\n",
        "\n",
        "Your extracted documents are ready for use in RAG systems.\n",
        "\n",
        "**Output locations:**\n",
        "- Individual JSONs: `data/processed/`\n",
        "- Combined JSONL: `Output/pdf_extraction.jsonl`\n",
        "- Logs: `logs/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary\n",
        "print(\"üéâ PIPELINE COMPLETE!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nüìÅ Output files in Google Drive:\")\n",
        "print(f\"   {project_path}/data/processed/\")\n",
        "print(f\"   {project_path}/Output/pdf_extraction.jsonl\")\n",
        "print(\"\\nüìã Next steps:\")\n",
        "print(\"   1. Download the JSONL file\")\n",
        "print(\"   2. Upload to your vector database\")\n",
        "print(\"   3. Use in your RAG application\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
